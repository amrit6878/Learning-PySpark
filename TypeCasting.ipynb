{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwccF9jU0oVuK6uihm4Z4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrit6878/Learning-PySpark/blob/main/TypeCasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting a column’s data type to another type.\n",
        "\n",
        "Commonly required when:\n",
        "\n",
        "\t1.\tReading data from CSV/JSON where numbers are read as string.\n",
        "\t2.\tPreparing data for joins, aggregations, or mathematical operations.\n",
        "\t3.\tEnsuring schema consistency in ETL pipelines.\n",
        "\n",
        "  .cast()\n",
        "  \n",
        "  withColumn() → Create a new column or replace an existing column with casted type."
      ],
      "metadata": {
        "id": "KBXQI0lpxCbn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDJBEMWcw0Ou",
        "outputId": "4f6522e8-78b3-4371-d17f-90f19a19a920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            " |-- JoiningDate: string (nullable = true)\n",
            "\n",
            "+---+-------+----+--------+-------------------+\n",
            "|ID |Name   |Age |Salary  |JoiningDate        |\n",
            "+---+-------+----+--------+-------------------+\n",
            "|101|Alice  |25  |50000.50|2025-01-10 12:30:00|\n",
            "|102|Bob    |30  |60000.00|2025-02-15 09:15:00|\n",
            "|103|Charlie|NULL|55000.75|NULL               |\n",
            "+---+-------+----+--------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"TypeCastingExample\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"101\", \"Alice\", \"25\", \"50000.50\", \"2025-01-10 12:30:00\"),\n",
        "    (\"102\", \"Bob\", \"30\", \"60000.00\", \"2025-02-15 09:15:00\"),\n",
        "    (\"103\", \"Charlie\", None, \"55000.75\", None)\n",
        "]\n",
        "columns = [\"ID\", \"Name\", \"Age\", \"Salary\", \"JoiningDate\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Age to IntegerType:"
      ],
      "metadata": {
        "id": "UkHT79LMx6My"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cast = df.withColumn(\"Age_Int\", col(\"Age\").cast(\"int\"))\n",
        "df_cast.show()\n",
        "df_cast.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH6k8lPCxwx-",
        "outputId": "6e674106-5594-424c-9b42-1b13063f185b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+----+--------+-------------------+-------+\n",
            "| ID|   Name| Age|  Salary|        JoiningDate|Age_Int|\n",
            "+---+-------+----+--------+-------------------+-------+\n",
            "|101|  Alice|  25|50000.50|2025-01-10 12:30:00|     25|\n",
            "|102|    Bob|  30|60000.00|2025-02-15 09:15:00|     30|\n",
            "|103|Charlie|NULL|55000.75|               NULL|   NULL|\n",
            "+---+-------+----+--------+-------------------+-------+\n",
            "\n",
            "root\n",
            " |-- ID: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            " |-- JoiningDate: string (nullable = true)\n",
            " |-- Age_Int: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert ID → Integer, Age → Integer, Salary → Double"
      ],
      "metadata": {
        "id": "aW165iBCyM_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cast = df \\\n",
        "    .withColumn(\"ID_Int\", col(\"ID\").cast(\"int\")) \\\n",
        "    .withColumn(\"Age_Int\", col(\"Age\").cast(\"int\")) \\\n",
        "    .withColumn(\"Salary_Double\", col(\"Salary\").cast(\"double\"))\n",
        "\n",
        "df_cast.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hma4SpssyJjq",
        "outputId": "4c97f9d8-2c66-4c4f-80ea-12f86f9c0ec4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            " |-- JoiningDate: string (nullable = true)\n",
            " |-- ID_Int: integer (nullable = true)\n",
            " |-- Age_Int: integer (nullable = true)\n",
            " |-- Salary_Double: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using selectExpr() for Casting**\n",
        "\n"
      ],
      "metadata": {
        "id": "r0Q29wE_ylER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cast = df.selectExpr(\n",
        "    \"cast(ID as int) ID_Int\",\n",
        "    \"Name\",\n",
        "    \"cast(Age as int) Age_Int\",\n",
        "    \"cast(Salary as double) Salary_Double\"\n",
        ")\n",
        "df_cast.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXRSyGc7yq2E",
        "outputId": "5a07d433-5987-47e3-ca68-000bdbe06f35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID_Int: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age_Int: integer (nullable = true)\n",
            " |-- Salary_Double: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Invalid Values - using `na.fill() and when()/otherwise()` as conditional conversion Useful for:\n",
        "\n",
        "\t•\tConditional cleaning\n",
        "\t•\tHandling invalid data formats\n",
        "\t•\tSetting defaults"
      ],
      "metadata": {
        "id": "C8SVIcjNzaru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "spark = SparkSession.builder.appName(\"HandleInvalidData\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"101\", \"Alice\", \"25\", \"50000.50\"),\n",
        "    (\"102\", \"Bob\", None, \"abc\"),        # Invalid Salary\n",
        "    (\"103\", \"Charlie\", \"thirty\", \"55000.75\"), # Invalid Age\n",
        "    (\"104\", \"David\", None, None),       # Null Age and Salary\n",
        "    (\"105\", \"Eva\", \"40\", \"80000.00\")\n",
        "]\n",
        "columns = [\"ID\", \"Name\", \"Age\", \"Salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tznautoz7gl",
        "outputId": "306ccb6f-f835-433b-b768-87903f0d5885"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+--------+\n",
            "|ID |Name   |Age   |Salary  |\n",
            "+---+-------+------+--------+\n",
            "|101|Alice  |25    |50000.50|\n",
            "|102|Bob    |NULL  |abc     |\n",
            "|103|Charlie|thirty|55000.75|\n",
            "|104|David  |NULL  |NULL    |\n",
            "|105|Eva    |40    |80000.00|\n",
            "+---+-------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "na.fill() can replace NULL values with default values.\n"
      ],
      "metadata": {
        "id": "H_jQ2ytd0JEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled = df.na.fill({\"Age\": \"0\", \"Salary\": \"0.0\"})\n",
        "df_filled.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBb5iZcZ0F3A",
        "outputId": "f3d8dbdb-1465-49ed-f32f-6144ff35c178"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+--------+\n",
            "| ID|   Name|   Age|  Salary|\n",
            "+---+-------+------+--------+\n",
            "|101|  Alice|    25|50000.50|\n",
            "|102|    Bob|     0|     abc|\n",
            "|103|Charlie|thirty|55000.75|\n",
            "|104|  David|     0|     0.0|\n",
            "|105|    Eva|    40|80000.00|\n",
            "+---+-------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_extract\n",
        "\n",
        "# Keep only digits, else set 0\n",
        "df_age_clean = df_filled.withColumn(\n",
        "    \"Age_Int\",\n",
        "    when(col(\"Age\").rlike(\"^[0-9]+$\"), col(\"Age\").cast(\"int\")).otherwise(0)\n",
        ")\n",
        "df_age_clean.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr-jYNH80OYx",
        "outputId": "814c55ee-add5-4cdc-f36c-eda654cb9b78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+--------+-------+\n",
            "| ID|   Name|   Age|  Salary|Age_Int|\n",
            "+---+-------+------+--------+-------+\n",
            "|101|  Alice|    25|50000.50|     25|\n",
            "|102|    Bob|     0|     abc|      0|\n",
            "|103|Charlie|thirty|55000.75|      0|\n",
            "|104|  David|     0|     0.0|      0|\n",
            "|105|    Eva|    40|80000.00|     40|\n",
            "+---+-------+------+--------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}